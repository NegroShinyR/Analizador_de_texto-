Design Doc ‚Äì Text to Analixer üìù
1. Objetivo del sistema

El prop√≥sito del sistema Text to Analixer es analizar un texto en espa√±ol y calcular qu√© tan relacionado est√° con el campo de las Matem√°ticas, generando un puntaje en una escala del 0% al 100%.

El sistema fue dise√±ado con los siguientes objetivos:

  Proveer una herramienta sencilla para detectar contenido matem√°tico dentro de un texto.
  
  Servir como ejemplo pr√°ctico para cursos de:

    Procesamiento b√°sico de lenguaje natural (NLP simple),
    
    Manejo de bases de datos (PostgreSQL),
    
    Desarrollo r√°pido de interfaces web (Streamlit).

  Permitir probar textos diversos:

    Matem√°ticos puros,
    
    Textos mixtos con matem√°ticas integradas,
    
    Textos no matem√°ticos.

2. Arquitectura General

La arquitectura est√° dise√±ada para ser simple y f√°cilmente entendible:

Usuario ‚îÄ‚îÄ> Interfaz Streamlit (buscale.py)
             ‚îÇ
             ‚îú‚îÄ‚îÄ Carga vocabulario matem√°tico desde PostgreSQL
             ‚îÇ
             ‚îú‚îÄ‚îÄ Tokenizaci√≥n del texto
             ‚îÇ
             ‚îî‚îÄ‚îÄ Algoritmo MatCompat v5:
                 Calcula el puntaje con base en:
                   ‚óè Promedio de pesos de palabras matem√°ticas
                   ‚óè Densidad matem√°tica del texto

Componentes principales:

Frontend + Backend:
Todo el procesamiento y la interfaz est√°n unificados en buscale.py usando Streamlit.

Base de Datos:
Una tabla PostgreSQL llamada palabras_clave contiene:

t√©rminos matem√°ticos,

porcentaje de identidad (peso),

sin√≥nimos.

Algoritmo MatCompat v5:
Es un clasificador basado en vocabulario que mide:

relevancia promedio de t√©rminos matem√°ticos,

densidad matem√°tica.


3. Modelo de Datos
  3.1. Tabla public.palabras_clave

  Define el vocabulario matem√°tico.

  Campos:
  
  | Campo                  | Tipo         | Descripci√≥n                             |
  | ---------------------- | ------------ | --------------------------------------- |
  | `id`                   | SERIAL       | Identificador √∫nico                     |
  | `palabra`              | TEXT         | T√©rmino base (ej. ‚Äúderivada‚Äù, ‚Äúmatriz‚Äù) |
  | `porcentaje_identidad` | NUMERIC(5,2) | Peso (relevancia del t√©rmino)           |
  | `sinonimos`            | TEXT[]       | Lista de sin√≥nimos (sin espacios)       |


Ejemplo de registros:

    ("derivada", 97.00, ARRAY['derivadas','derivar'])
    
    ("matriz", 93.00, ARRAY['matrices'])
    
    ("integral", 97.00, ARRAY['integrales','integrar'])

3.2. √çndice en memoria

    Una vez que la app arranca, se transforma la tabla en un diccionario:
    
    token_normalizado  ‚Üí  (palabra_base, peso)
    
    Donde:
    
    token_normalizado: versi√≥n en min√∫sculas y sin acentos.
    
    palabra_base: t√©rmino original de la BD.
    
    peso: porcentaje_identidad convertido a n√∫mero entre 0 y 1.


4. Flujo de Ejecuci√≥n

  4.1.- Cargar vocabulario desde PostgreSQL
  
    Para no hacer consultas por cada token, se carga todo al inicio.
  
    Los sin√≥nimos se normalizan igual que los tokens del texto.
  
  4.2.- Usuario ingresa un texto
  
    Se usa un text_area de Streamlit.
  
  4.3.- Tokenizaci√≥n
  
    min√∫sculas,
  
    eliminaci√≥n de acentos,
  
    separaci√≥n por expresiones regulares,
  
    filtrado de stopwords en espa√±ol.
  
  4.4.-Coincidencias matem√°ticas
  
    Por cada token:
  
      Si existe en vocab_index, cuenta como ‚Äút√©rmino matem√°tico‚Äù.
  
  4.5.- C√°lculo de m√©tricas
  
    avg_peso: promedio de pesos de t√©rminos encontrados.
  
    densidad_matematica: proporci√≥n de tokens significativos que son matem√°ticos.
  
    distinct_terms: n√∫mero de t√©rminos matem√°ticos diferentes.
  
  4.6.-C√°lculo del puntaje
  
    Se aplica el algoritmo MatCompat v5:
    score = 100 * (0.55 * avg_peso + 0.45 * densidad_matematica)
  
  4.7.-Presentaci√≥n
  
    Barra de compatibilidad,
  
    M√©tricas auxiliares,
  
    Tabla con t√©rminos matem√°ticos encontrados ordenados por aporte.

5. Decisiones de Dise√±o
  ‚úî Uso de PostgreSQL en lugar de listas en Python
  
        Separaci√≥n entre datos y l√≥gica.
        
        F√°cil de ampliar sin tocar c√≥digo.
        
        Control de calidad (CHECK, triggers, normalizaci√≥n).

  ‚úî Normalizaci√≥n unificada
  
    Se aplica la misma normalizaci√≥n a:
    
    texto del usuario,
    
    palabras base,
    
    sin√≥nimos.

    Esto asegura coincidencias consistentes aun si el usuario escribe:

    ‚Äúc√°lculo‚Äù, ‚Äúcalculo‚Äù, ‚ÄúCalCULO‚Äù, ‚ÄúcalÃÅculo‚Äù.

  ‚úî Clases simples en lugar de IA pesada

    El algoritmo se basa en vocabulario y densidad:
    
    F√°cil de explicar en clase,
    
    No requiere GPU,
    
    No necesita modelos entrenados.

  ‚úî Streamlit

    F√°cil de usar para proyectos escolares,
    
    Genera interfaces limpias sin HTML/CSS,
    
    Ideal para una demo interactiva.

